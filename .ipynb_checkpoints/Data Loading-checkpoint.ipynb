{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5bd049-53cd-40eb-bb09-bfc2453a52bd",
   "metadata": {},
   "source": [
    "# Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df6b8146-aa2f-40a4-a502-a400865479e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris() #Return a Bunch object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86d90222-5470-49f0-a4b6-733aa16a5709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82ffce2-39ec-4e43-943f-80c8d4365253",
   "metadata": {},
   "source": [
    "Contains i) data ii) target iii) feature_names iv)target_names v)DESCR vi) filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d2b4875-fb16-4dd4-a79a-0de00c0bedbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f7a329a-00ca-47d4-bf6c-971479f22fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d07715bd-f113-41d1-b649-86b69185aad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data[:5] #First five rows from feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1779af4-9bf9-451d-a49f-376b49175a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names #Lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc3332b7-905b-4b37-a6f1-d22c162009f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e104c498-3d07-49dc-b38c-282e4c3e67e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_X_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_frame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Load and return the iris dataset (classification).\n",
       "\n",
       "The iris dataset is a classic and very easy multi-class classification\n",
       "dataset.\n",
       "\n",
       "=================   ==============\n",
       "Classes                          3\n",
       "Samples per class               50\n",
       "Samples total                  150\n",
       "Dimensionality                   4\n",
       "Features            real, positive\n",
       "=================   ==============\n",
       "\n",
       "Read more in the :ref:`User Guide <iris_dataset>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "return_X_y : bool, default=False\n",
       "    If True, returns ``(data, target)`` instead of a Bunch object. See\n",
       "    below for more information about the `data` and `target` object.\n",
       "\n",
       "    .. versionadded:: 0.18\n",
       "\n",
       "as_frame : bool, default=False\n",
       "    If True, the data is a pandas DataFrame including columns with\n",
       "    appropriate dtypes (numeric). The target is\n",
       "    a pandas DataFrame or Series depending on the number of target columns.\n",
       "    If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
       "    DataFrames or Series as described below.\n",
       "\n",
       "    .. versionadded:: 0.23\n",
       "\n",
       "Returns\n",
       "-------\n",
       "data : :class:`~sklearn.utils.Bunch`\n",
       "    Dictionary-like object, with the following attributes.\n",
       "\n",
       "    data : {ndarray, dataframe} of shape (150, 4)\n",
       "        The data matrix. If `as_frame=True`, `data` will be a pandas\n",
       "        DataFrame.\n",
       "    target: {ndarray, Series} of shape (150,)\n",
       "        The classification target. If `as_frame=True`, `target` will be\n",
       "        a pandas Series.\n",
       "    feature_names: list\n",
       "        The names of the dataset columns.\n",
       "    target_names: list\n",
       "        The names of target classes.\n",
       "    frame: DataFrame of shape (150, 5)\n",
       "        Only present when `as_frame=True`. DataFrame with `data` and\n",
       "        `target`.\n",
       "\n",
       "        .. versionadded:: 0.23\n",
       "    DESCR: str\n",
       "        The full description of the dataset.\n",
       "    filename: str\n",
       "        The path to the location of the data.\n",
       "\n",
       "        .. versionadded:: 0.20\n",
       "\n",
       "(data, target) : tuple if ``return_X_y`` is True\n",
       "\n",
       "    .. versionadded:: 0.18\n",
       "\n",
       "Notes\n",
       "-----\n",
       "    .. versionchanged:: 0.20\n",
       "        Fixed two wrong data points according to Fisher's paper.\n",
       "        The new version is the same as in R, but not as in the UCI\n",
       "        Machine Learning Repository.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Let's say you are interested in the samples 10, 25, and 50, and want to\n",
       "know their class name.\n",
       "\n",
       ">>> from sklearn.datasets import load_iris\n",
       ">>> data = load_iris()\n",
       ">>> data.target[[10, 25, 50]]\n",
       "array([0, 0, 1])\n",
       ">>> list(data.target_names)\n",
       "['setosa', 'versicolor', 'virginica']\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\viswa\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_base.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?load_iris "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7346cca-3bab-4aab-b5b8-41b36faf7865",
   "metadata": {},
   "source": [
    "We can make the load function output tuples of fetures and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fe1b42d-8e49-4136-8123-5c062f9e648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, label_vector = load_iris(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "879c9618-beb7-4b9e-873f-4dd2d08e581c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature matrix: (150, 4)\n",
      "Shape of label vector: (150,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of feature matrix:\", feature_matrix.shape)\n",
    "print(\"Shape of label vector:\", label_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4c190-4b7f-4f6f-8ec6-20332511b7c4",
   "metadata": {},
   "source": [
    "## Loading Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e729bde3-498d-45f5-b71b-95651adc39ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "data = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52a20839-6cd2-49ec-8a1c-d391f4d682d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, T-Cells (a type of white blood cells)\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, thyroid stimulating hormone\\n      - s5      ltg, lamotrigine\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c012de8d-b043-48bf-a22c-8beaa0ad2746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621,  0.02187235, -0.0442235 ,\n",
       "        -0.03482076, -0.04340085, -0.00259226,  0.01990842, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, -0.02632783, -0.00844872,\n",
       "        -0.01916334,  0.07441156, -0.03949338, -0.06832974, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, -0.00567061, -0.04559945,\n",
       "        -0.03419447, -0.03235593, -0.00259226,  0.00286377, -0.02593034],\n",
       "       [-0.08906294, -0.04464164, -0.01159501, -0.03665645,  0.01219057,\n",
       "         0.02499059, -0.03603757,  0.03430886,  0.02269202, -0.00936191],\n",
       "       [ 0.00538306, -0.04464164, -0.03638469,  0.02187235,  0.00393485,\n",
       "         0.01559614,  0.00814208, -0.00259226, -0.03199144, -0.04664087]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11854b48-5153-4a6a-a804-e9db116e1b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "217bedbd-d912-4ccb-a7ef-226cba3741ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e42def7-43f5-4f34-84ea-74674f29812f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac1472-6f1e-431e-b6fe-ac167474d9a5",
   "metadata": {},
   "source": [
    "# Fetchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2039a164-f9de-4f94-95a6-184a3542ed5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mfetch_california_housing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdata_home\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdownload_if_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreturn_X_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mas_frame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Load the California housing dataset (regression).\n",
       "\n",
       "==============   ==============\n",
       "Samples total             20640\n",
       "Dimensionality                8\n",
       "Features                   real\n",
       "Target           real 0.15 - 5.\n",
       "==============   ==============\n",
       "\n",
       "Read more in the :ref:`User Guide <california_housing_dataset>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data_home : str, default=None\n",
       "    Specify another download and cache folder for the datasets. By default\n",
       "    all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
       "\n",
       "download_if_missing : bool, default=True\n",
       "    If False, raise a IOError if the data is not locally available\n",
       "    instead of trying to download the data from the source site.\n",
       "\n",
       "\n",
       "return_X_y : bool, default=False.\n",
       "    If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
       "    object.\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "as_frame : bool, default=False\n",
       "    If True, the data is a pandas DataFrame including columns with\n",
       "    appropriate dtypes (numeric, string or categorical). The target is\n",
       "    a pandas DataFrame or Series depending on the number of target_columns.\n",
       "\n",
       "    .. versionadded:: 0.23\n",
       "\n",
       "Returns\n",
       "-------\n",
       "dataset : :class:`~sklearn.utils.Bunch`\n",
       "    Dictionary-like object, with the following attributes.\n",
       "\n",
       "    data : ndarray, shape (20640, 8)\n",
       "        Each row corresponding to the 8 feature values in order.\n",
       "        If ``as_frame`` is True, ``data`` is a pandas object.\n",
       "    target : numpy array of shape (20640,)\n",
       "        Each value corresponds to the average\n",
       "        house value in units of 100,000.\n",
       "        If ``as_frame`` is True, ``target`` is a pandas object.\n",
       "    feature_names : list of length 8\n",
       "        Array of ordered feature names used in the dataset.\n",
       "    DESCR : string\n",
       "        Description of the California housing dataset.\n",
       "    frame : pandas DataFrame\n",
       "        Only present when `as_frame=True`. DataFrame with ``data`` and\n",
       "        ``target``.\n",
       "\n",
       "        .. versionadded:: 0.23\n",
       "\n",
       "(data, target) : tuple if ``return_X_y`` is True\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\n",
       "This dataset consists of 20,640 samples and 9 features.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\viswa\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_california_housing.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "?fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab74b996-fca7-41ee-a4a2-f43aa5876679",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5cb7178f-a4ac-47d8-91f3-f74daa706342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(housing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5233e9b-38ee-46ad-8862-e6379a2bfd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1429ae1-57e1-49ad-930d-f9cc161dea1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cde1477-bc60-48ce-99d2-1ed65aa67bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d219082-aa05-4290-9262-6d9d8c01f4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.32520000e+00,  4.10000000e+01,  6.98412698e+00,\n",
       "         1.02380952e+00,  3.22000000e+02,  2.55555556e+00,\n",
       "         3.78800000e+01, -1.22230000e+02],\n",
       "       [ 8.30140000e+00,  2.10000000e+01,  6.23813708e+00,\n",
       "         9.71880492e-01,  2.40100000e+03,  2.10984183e+00,\n",
       "         3.78600000e+01, -1.22220000e+02],\n",
       "       [ 7.25740000e+00,  5.20000000e+01,  8.28813559e+00,\n",
       "         1.07344633e+00,  4.96000000e+02,  2.80225989e+00,\n",
       "         3.78500000e+01, -1.22240000e+02],\n",
       "       [ 5.64310000e+00,  5.20000000e+01,  5.81735160e+00,\n",
       "         1.07305936e+00,  5.58000000e+02,  2.54794521e+00,\n",
       "         3.78500000e+01, -1.22250000e+02],\n",
       "       [ 3.84620000e+00,  5.20000000e+01,  6.28185328e+00,\n",
       "         1.08108108e+00,  5.65000000e+02,  2.18146718e+00,\n",
       "         3.78500000e+01, -1.22250000e+02]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5527df2e-56e4-4a32-8eab-bd995825e281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, 3.413, 3.422])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6b4f942-b5a0-4bf9-bea1-a266f5f7f4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedHouseVal']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "80c5efc7-89f9-4a30-9f0e-492cf4edaf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block\\n        - HouseAge      median house age in block\\n        - AveRooms      average number of rooms\\n        - AveBedrms     average number of bedrooms\\n        - Population    block population\\n        - AveOccup      average house occupancy\\n        - Latitude      house block latitude\\n        - Longitude     house block longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttp://lib.stat.cmu.edu/datasets/\\n\\nThe target variable is the median house value for California districts.\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b1a798-2af1-4fcc-9ea8-0455e85b613a",
   "metadata": {},
   "source": [
    "# Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49598346-190c-45e4-b9ac-161b32170db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mmake_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_informative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_targets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0meffective_rank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtail_strength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcoef\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Generate a random regression problem.\n",
       "\n",
       "The input set can either be well conditioned (by default) or have a low\n",
       "rank-fat tail singular profile. See :func:`make_low_rank_matrix` for\n",
       "more details.\n",
       "\n",
       "The output is generated by applying a (potentially biased) random linear\n",
       "regression model with `n_informative` nonzero regressors to the previously\n",
       "generated input and some gaussian centered noise with some adjustable\n",
       "scale.\n",
       "\n",
       "Read more in the :ref:`User Guide <sample_generators>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "n_samples : int, default=100\n",
       "    The number of samples.\n",
       "\n",
       "n_features : int, default=100\n",
       "    The number of features.\n",
       "\n",
       "n_informative : int, default=10\n",
       "    The number of informative features, i.e., the number of features used\n",
       "    to build the linear model used to generate the output.\n",
       "\n",
       "n_targets : int, default=1\n",
       "    The number of regression targets, i.e., the dimension of the y output\n",
       "    vector associated with a sample. By default, the output is a scalar.\n",
       "\n",
       "bias : float, default=0.0\n",
       "    The bias term in the underlying linear model.\n",
       "\n",
       "effective_rank : int, default=None\n",
       "    if not None:\n",
       "        The approximate number of singular vectors required to explain most\n",
       "        of the input data by linear combinations. Using this kind of\n",
       "        singular spectrum in the input allows the generator to reproduce\n",
       "        the correlations often observed in practice.\n",
       "    if None:\n",
       "        The input set is well conditioned, centered and gaussian with\n",
       "        unit variance.\n",
       "\n",
       "tail_strength : float, default=0.5\n",
       "    The relative importance of the fat noisy tail of the singular values\n",
       "    profile if `effective_rank` is not None. When a float, it should be\n",
       "    between 0 and 1.\n",
       "\n",
       "noise : float, default=0.0\n",
       "    The standard deviation of the gaussian noise applied to the output.\n",
       "\n",
       "shuffle : bool, default=True\n",
       "    Shuffle the samples and the features.\n",
       "\n",
       "coef : bool, default=False\n",
       "    If True, the coefficients of the underlying linear model are returned.\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    Determines random number generation for dataset creation. Pass an int\n",
       "    for reproducible output across multiple function calls.\n",
       "    See :term:`Glossary <random_state>`.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "X : ndarray of shape (n_samples, n_features)\n",
       "    The input samples.\n",
       "\n",
       "y : ndarray of shape (n_samples,) or (n_samples, n_targets)\n",
       "    The output values.\n",
       "\n",
       "coef : ndarray of shape (n_features,) or (n_features, n_targets)\n",
       "    The coefficient of the underlying linear model. It is returned only if\n",
       "    coef is True.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\viswa\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_samples_generator.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "?make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b4327d7-6e1d-4160-a14a-bffb9c1fc949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=100, n_features=5, n_targets=1, shuffle=True, random_state=45)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aecf7514-c7b6-432f-9298-6214cfad6d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ef8a05b-7473-447c-9157-5e8fd78f7bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=100, n_features=5, n_targets=5, shuffle=True, random_state=45)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f757878-9f22-482d-8fc1-41cc6efa1636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a2faddc9-f5c3-40d4-987c-c26a131bd3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mmake_classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_informative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_redundant\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_repeated\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_clusters_per_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mflip_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclass_sep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mhypercube\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mshift\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Generate a random n-class classification problem.\n",
       "\n",
       "This initially creates clusters of points normally distributed (std=1)\n",
       "about vertices of an ``n_informative``-dimensional hypercube with sides of\n",
       "length ``2*class_sep`` and assigns an equal number of clusters to each\n",
       "class. It introduces interdependence between these features and adds\n",
       "various types of further noise to the data.\n",
       "\n",
       "Without shuffling, ``X`` horizontally stacks features in the following\n",
       "order: the primary ``n_informative`` features, followed by ``n_redundant``\n",
       "linear combinations of the informative features, followed by ``n_repeated``\n",
       "duplicates, drawn randomly with replacement from the informative and\n",
       "redundant features. The remaining features are filled with random noise.\n",
       "Thus, without shuffling, all useful features are contained in the columns\n",
       "``X[:, :n_informative + n_redundant + n_repeated]``.\n",
       "\n",
       "Read more in the :ref:`User Guide <sample_generators>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "n_samples : int, default=100\n",
       "    The number of samples.\n",
       "\n",
       "n_features : int, default=20\n",
       "    The total number of features. These comprise ``n_informative``\n",
       "    informative features, ``n_redundant`` redundant features,\n",
       "    ``n_repeated`` duplicated features and\n",
       "    ``n_features-n_informative-n_redundant-n_repeated`` useless features\n",
       "    drawn at random.\n",
       "\n",
       "n_informative : int, default=2\n",
       "    The number of informative features. Each class is composed of a number\n",
       "    of gaussian clusters each located around the vertices of a hypercube\n",
       "    in a subspace of dimension ``n_informative``. For each cluster,\n",
       "    informative features are drawn independently from  N(0, 1) and then\n",
       "    randomly linearly combined within each cluster in order to add\n",
       "    covariance. The clusters are then placed on the vertices of the\n",
       "    hypercube.\n",
       "\n",
       "n_redundant : int, default=2\n",
       "    The number of redundant features. These features are generated as\n",
       "    random linear combinations of the informative features.\n",
       "\n",
       "n_repeated : int, default=0\n",
       "    The number of duplicated features, drawn randomly from the informative\n",
       "    and the redundant features.\n",
       "\n",
       "n_classes : int, default=2\n",
       "    The number of classes (or labels) of the classification problem.\n",
       "\n",
       "n_clusters_per_class : int, default=2\n",
       "    The number of clusters per class.\n",
       "\n",
       "weights : array-like of shape (n_classes,) or (n_classes - 1,),              default=None\n",
       "    The proportions of samples assigned to each class. If None, then\n",
       "    classes are balanced. Note that if ``len(weights) == n_classes - 1``,\n",
       "    then the last class weight is automatically inferred.\n",
       "    More than ``n_samples`` samples may be returned if the sum of\n",
       "    ``weights`` exceeds 1. Note that the actual class proportions will\n",
       "    not exactly match ``weights`` when ``flip_y`` isn't 0.\n",
       "\n",
       "flip_y : float, default=0.01\n",
       "    The fraction of samples whose class is assigned randomly. Larger\n",
       "    values introduce noise in the labels and make the classification\n",
       "    task harder. Note that the default setting flip_y > 0 might lead\n",
       "    to less than ``n_classes`` in y in some cases.\n",
       "\n",
       "class_sep : float, default=1.0\n",
       "    The factor multiplying the hypercube size.  Larger values spread\n",
       "    out the clusters/classes and make the classification task easier.\n",
       "\n",
       "hypercube : bool, default=True\n",
       "    If True, the clusters are put on the vertices of a hypercube. If\n",
       "    False, the clusters are put on the vertices of a random polytope.\n",
       "\n",
       "shift : float, ndarray of shape (n_features,) or None, default=0.0\n",
       "    Shift features by the specified value. If None, then features\n",
       "    are shifted by a random value drawn in [-class_sep, class_sep].\n",
       "\n",
       "scale : float, ndarray of shape (n_features,) or None, default=1.0\n",
       "    Multiply features by the specified value. If None, then features\n",
       "    are scaled by a random value drawn in [1, 100]. Note that scaling\n",
       "    happens after shifting.\n",
       "\n",
       "shuffle : bool, default=True\n",
       "    Shuffle the samples and the features.\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    Determines random number generation for dataset creation. Pass an int\n",
       "    for reproducible output across multiple function calls.\n",
       "    See :term:`Glossary <random_state>`.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "X : ndarray of shape (n_samples, n_features)\n",
       "    The generated samples.\n",
       "\n",
       "y : ndarray of shape (n_samples,)\n",
       "    The integer labels for class membership of each sample.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The algorithm is adapted from Guyon [1] and was designed to generate\n",
       "the \"Madelon\" dataset.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
       "       selection benchmark\", 2003.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "make_blobs : Simplified variant.\n",
       "make_multilabel_classification : Unrelated generator for multilabel tasks.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\viswa\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_samples_generator.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "?make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fee89008-1475-492a-a282-ca2f08aac9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100, n_features=10, n_classes=2, n_clusters_per_class=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "faabe85e-3bc6-47de-9450-5b1a7cb2172f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ce84261-b66a-4e02-be05-af0670f9138f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff139486-f809-4ae8-a75b-6e5af5030bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 20)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification \n",
    "X, y = make_multilabel_classification(n_samples=100, n_features=20, n_classes=5, n_labels=2)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "db7da4b3-9df0-4e5f-ac77-376742f3451f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8751b0d-d113-48e9-9df4-e794eac0346a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mmake_blobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcenters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcluster_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcenter_box\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreturn_centers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Generate isotropic Gaussian blobs for clustering.\n",
       "\n",
       "Read more in the :ref:`User Guide <sample_generators>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "n_samples : int or array-like, default=100\n",
       "    If int, it is the total number of points equally divided among\n",
       "    clusters.\n",
       "    If array-like, each element of the sequence indicates\n",
       "    the number of samples per cluster.\n",
       "\n",
       "    .. versionchanged:: v0.20\n",
       "        one can now pass an array-like to the ``n_samples`` parameter\n",
       "\n",
       "n_features : int, default=2\n",
       "    The number of features for each sample.\n",
       "\n",
       "centers : int or ndarray of shape (n_centers, n_features), default=None\n",
       "    The number of centers to generate, or the fixed center locations.\n",
       "    If n_samples is an int and centers is None, 3 centers are generated.\n",
       "    If n_samples is array-like, centers must be\n",
       "    either None or an array of length equal to the length of n_samples.\n",
       "\n",
       "cluster_std : float or array-like of float, default=1.0\n",
       "    The standard deviation of the clusters.\n",
       "\n",
       "center_box : tuple of float (min, max), default=(-10.0, 10.0)\n",
       "    The bounding box for each cluster center when centers are\n",
       "    generated at random.\n",
       "\n",
       "shuffle : bool, default=True\n",
       "    Shuffle the samples.\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    Determines random number generation for dataset creation. Pass an int\n",
       "    for reproducible output across multiple function calls.\n",
       "    See :term:`Glossary <random_state>`.\n",
       "\n",
       "return_centers : bool, default=False\n",
       "    If True, then return the centers of each cluster\n",
       "\n",
       "    .. versionadded:: 0.23\n",
       "\n",
       "Returns\n",
       "-------\n",
       "X : ndarray of shape (n_samples, n_features)\n",
       "    The generated samples.\n",
       "\n",
       "y : ndarray of shape (n_samples,)\n",
       "    The integer labels for cluster membership of each sample.\n",
       "\n",
       "centers : ndarray of shape (n_centers, n_features)\n",
       "    The centers of each cluster. Only returned if\n",
       "    ``return_centers=True``.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.datasets import make_blobs\n",
       ">>> X, y = make_blobs(n_samples=10, centers=3, n_features=2,\n",
       "...                   random_state=0)\n",
       ">>> print(X.shape)\n",
       "(10, 2)\n",
       ">>> y\n",
       "array([0, 0, 1, 0, 2, 2, 2, 1, 1, 0])\n",
       ">>> X, y = make_blobs(n_samples=[3, 3, 4], centers=None, n_features=2,\n",
       "...                   random_state=0)\n",
       ">>> print(X.shape)\n",
       "(10, 2)\n",
       ">>> y\n",
       "array([0, 1, 2, 0, 2, 2, 2, 1, 1, 0])\n",
       "\n",
       "See Also\n",
       "--------\n",
       "make_classification : A more intricate variant.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\viswa\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_samples_generator.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "?make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "429b8bd9-5949-4730-9547-a4558bb26f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_blobs(n_samples=10, centers=3, n_features=2, random_state=42)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d7c7e540-88ec-4816-bf36-00369d4239ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "00e4266d-c208-4093-94cf-9c0b29483eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3ee0df36-718e-4b8f-a763-83411cacec19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c06c895a-a3b0-4bb3-b4d9-7669212eb62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "974c5504-2701-45ac-832a-f5c950f37556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f6b48-8bc2-456b-bd81-3084a25ef7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
